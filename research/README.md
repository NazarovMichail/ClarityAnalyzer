# Результаты тестирования моделей

## Сравнительная таблица

| Classifier                         | Val Score | Train Score | Overfitting |
|------------------------------------|-----------|-------------|-------------|
| LogisticRegression L1              | 0.78      | 0.832       | 0.052       |
| LogisticRegression L2              | 0.775     | 0.808       | 0.033       |
| LogisticRegression ElasticNet      | 0.779     | 0.841       | 0.062       |
| PassiveAggressiveClassifier        | 0.705     | 0.822       | 0.117       |
| SGDClassifier                      | 0.781     | 0.83        | 0.049       |
| SVC                                | 0.7       | 0.999       | 0.299       |
| NuSVC rbf                          | 0.776     | 1           | 0.224       |
| NuSVC poly                         | 0.78      | 0.863       |             |
| LinearSVC                          |           | 0.731       | 0.731       |
| MLPClassifier                      | 0.76      | 0.832       | 0.072       |
| DecisionTreeClassifier             |           |             | 0           |
| ExtraTreesClassifier               | 0.73      | 0.78        | 0.05        |
| AdaBoostClassifier                 | 0.612     | 0.639       | 0.027       |
| HistGradientBoostingClassifier     | 0.762     | 0.963       | 0.201       |
| BaggingClassifier                  | 0.655     | 0.916       | 0.261       |
| VotingClassifier                   | 0.782     | 0.847       | 0.065       |
| StackingClassifier                 | 0.772     | 0.861       | 0.089       |
| beelineNN                          | 0.806     | 0.812       | 0.006       |
| CatBoost                           | 0.772     |             | -0.772      |
| LightGBM                           | 0.752     | 0.834       | 0.082       |
| XGBoost                            | 0.757     | 0.87        | 0.113       |
| KNeighborsClassifier               | 0.688     | 1           | 0.312       |
| RadiusNeighborsClassifier          | 0.705     | 0.727       | 0.022       |
| GaussianNB                         | 0.722     | 0.738       | 0.016       |
| BernoulliNB                        | 0.72      | 0.743       | 0.023       |
| ComplementNB                       | 0.72      | 0.734       | 0.014       |
| MultinomialNB                      | 0.718     | 0.728       | 0.01        |
| LinearDiscriminantAnalysis         | 0.782     | 0.831       | 0.049       |
| QuadraticDiscriminantAnalysis      | 0.739     | 0.837       | 0.098       |
| GaussianProcessClassifier          | 0.775     | 0.862       | 0.087       |
| Naive Bayes (MultinomialNB())      | 0.677     | 0.766       | 0.089       |
| LogisticRegression L2              | 0.681     | 0.823       | 0.142       |
| LogisticRegression L1              | 0.669     | 0.817       | 0.148       |
| SVM                                | 0.684     | 0.962       | 0.278       |
| XGBoost                            | 0.669     | 0.803       | 0.134       |
| Naive Bayes (MultinomialNB())      | 0.684     | 0.881       | 0.197       |
| LogisticRegression L2              | 0.685     | 0.969       | 0.284       |
| LogisticRegression L1              | 0.665     | 0.708       | 0.043       |
| SVM                                | 0.687     | 0.998       | 0.311       |
| XGBoost                            | 0.66      | 0.856       | 0.196       |

<img src='./img/classifier_scores.png'>

## Результат тестирования ручной нормализации с моделью токенизации sbert
Тестирование приведено в ноутбуке [sbert_normalization_test](https://github.com/kosatchev/ClarityAnalyzer/blob/636410cc88ab1a55d1e1e9516b92d0f90a8741c7/research/sbert_normalization_test.ipynb).

Проверяли, влияет ли предварительная обработка текста на результат токенизации. Тестировали наличие в "сыром" тексте:
* заглавных букв,
* знаков препинания,
* разного формата записи чисел (цифрами или буквами),
* взаимозаменяемых букв "ё" и "е".

**Выводы:**

Модель sbert "из коробки" обрабатывает заглавные буквы и взаимозаменяемость "ё" и "е".

А вот знаки препинания и формат записи чисел на результат токенизации влияют.

Датасет, с которым мы работаем в рамках хакатона, уже предобработан: только маленькие буквы, нет знаков препинания, нет букв "ё", все числа записаны текстом.

Однако это касается только train столбца (результата распознавания моделью ASR). В ручной разметке встречаются буквы "ё" и запятые. Также в ручной разметке встречается дублирование гласных для передачи эмоциональной окраски (например, "эээ" вместо "э"). Учитывая, что ручная разметка участвует в расчете WER для определения метки класса, часть уже проставленных классов может быть некорректной.

Если нужно расширить датасет или провести тестирование на данных не из тестовой части данного датасета, то стоит привести все данные к единому формату. Это также касается и ручной разметки, но в этом случае, вероятно, придется заново оценить метки классов для всего датасета.